\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsfonts, enumitem, graphicx}
\usepackage{nth}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{mathrsfs}
\usepackage{mathtools}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\renewcommand*{\proofname}{Solution}
\renewcommand{\theenumi}{\alph{enumi}}

\newcommand{\vc}[1]{\boldsymbol{#1}}

\newenvironment{amatrix}[1]{%
  \left[\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right]
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\grstep}[2][\relax]{%
   \ensuremath{\mathrel{
       {\mathop{\longrightarrow}\limits^{#2\mathstrut}_{
                                     \begin{subarray}{l} #1 \end{subarray}}}}}}
\newcommand{\swap}{\leftrightarrow}
\newcommand{\tran}{\mathsf{T}}
\newtheorem{theorem}{Theorem}



\pagestyle{fancy}
\fancyhf{}
\rhead{Homework Assignment 7}
\lhead{Matthew Tiger}
\cfoot{\thepage}


\title{Homework Assignment 7}
\author{Matthew Tiger}


\begin{document}


\maketitle


% Problem 1
\begin{problem}
  State all of the KKT conditions for $(N$-$\max)$. More precisely state all of the following
  results for $(N$-$\max)$: KKT-FONC, KKT-FOSC, KKT-SONC, KKT-SOSC.
\end{problem}

\begin{proof}
  For the following theorems, we assume $(N\text{-}\max)$ has the following form
  \begin{align*}
    \begin{array}{rrll}
      (N\text{-}\max) & \text{maximize} & f(\vc{x}) & \\
      & \text{subject to} & \vc{h}(\vc{x}) &= \vc{0} \\
      & & \vc{g}(\vc{x}) &\leq \vc{0} \\
    \end{array}
  \end{align*}
  where $f:\mathbb{R}^n\to\mathbb{R}$, $\vc{h}:\mathbb{R}^n \to \mathbb{R}^m$, and $\vc{g}:\mathbb{R}^n \to \mathbb{R}^p$ with $m \leq n$.
  Additionally, define the following Lagrangian function to be
  $\vc{L}(\vc{x}, \vc{\lambda}, \vc{\mu}) := -f(\vc{x}) + \vc{\lambda}^\tran\vc{h}(\vc{x}) + \vc{\mu}^\tran\vc{g}(\vc{x})$.

  \begin{theorem}[KKT-FONC for $(N\text{-}\max)$]
    Let $f$, $\vc{g}$, $\vc{h} \in C^1$ and let
    $\vc{x}^*$ be a regular point and local maximizer for the problem $(N\text{-}\max)$. Then,
    there exist $\vc{\lambda}^*\in\mathbb{R}^m$
    and $\vc{\mu}^* \in \mathbb{R}^p$ such that:
    \begin{enumerate}[label=\roman*.]
      \item $\vc{\mu}^* \geq \vc{0}.$
      \item $D_{\vc{x}}\vc{L}(\vc{x}^*, \vc{\lambda}^*, \vc{\mu}^*) = - Df(\vc{x}^*) + \vc{\lambda}^{*\tran}D\vc{h}(\vc{x}^*) + \vc{\mu}^{*\tran}D\vc{g}(\vc{x}^*)= \vc{0}^\tran$.
      \item $\mu^{*\tran}\vc{g}(\vc{x}^*) = 0$.
    \end{enumerate}
  Note that there are no explicit first-order conditions that are sufficient
  in general to show optimality.
  \end{theorem}

  \begin{theorem}[KKT-SONC for $(N\text{-}\max)$]
    Let $f$, $\vc{g}$, $\vc{h} \in C^2$ and let
    $\vc{x}^*$ be a regular point and local maximizer for the problem $(N\text{-}\max)$. Then,
    there exist $\vc{\lambda}^*\in\mathbb{R}^m$
    and $\vc{\mu}^* \in \mathbb{R}^p$ such that:
    \begin{enumerate}[label=\roman*.]
      \item $\vc{\mu}^* \geq \vc{0}$, $D_{\vc{x}}\vc{L}(\vc{x}^*, \vc{\lambda}^*, \vc{\mu}^*) = \vc{0}^\tran$, $\mu^{*\tran}\vc{g}(\vc{x}^*) = 0$.
      \item For all $\vc{y}\in T(\vc{x}^*) = \{\vc{y}\ |\ D\vc{h}(\vc{x}^*)\vc{y}=\vc{0}, Dg_j(\vc{x}^*)\vc{y} = 0, j \in J(\vc{x}^*)\}$, we have that $\vc{y}^\tran D_{\vc{x}}^2\vc{L}(\vc{x}^*, \vc{\lambda}^*, \vc{\mu}^*)\vc{y} \leq 0$.
    \end{enumerate}
  \end{theorem}

  \begin{theorem}[KKT-SOSC for $(N\text{-}\max)$]
    Let $f$, $\vc{g}$, $\vc{h} \in C^2$ and suppose there exists a feasible point
    $\vc{x}^*$ and vectors $\vc{\lambda}^*\in\mathbb{R}^m$
    and $\vc{\mu}^* \in \mathbb{R}^p$ such that:
    \begin{enumerate}[label=\roman*.]
      \item $\vc{\mu}^* \geq \vc{0}$, $D_x\vc{L}(\vc{x}^*, \vc{\lambda}^*, \vc{\mu}^*) = \vc{0}^\tran$, $\mu^{*\tran}\vc{g}(\vc{x}^*) = 0$.
      \item For all
        \begin{align*}
          \vc{y}\in \widetilde{T}(\vc{x}^*, \vc{\mu}^*) = \{\vc{y}\ |\ D\vc{h}(\vc{x}^*)\vc{y} = \vc{0}, Dg_i(\vc{x}^*)\vc{y} = 0, \text{for $i \in \{i\ |\ g_i(\vc{x}^*) = 0, \mu_i^* > 0\}$}\},
        \end{align*}
        with $\vc{y} \neq \vc{0}$, we have that $\vc{y}^\tran D_{\vc{x}}^2\vc{L}(\vc{x}^*, \vc{\lambda}^*, \vc{\mu}^*)\vc{y} < 0$.
    \end{enumerate}
    Then $\vc{x}^*$ is a strict local maximizer for the problem $(N\text{-}\max)$.
  \end{theorem}
\end{proof}
\newpage


% Problem 2
\begin{problem}
  Find local minimizers for
  \begin{align*}
    \begin{array}{rrl}
      (N\text{-}\min) & \text{minimize} & x_1^2 + 6x_1x_2 -4x_1 -2x_2\\
      & \text{subject to} & x_1^2 + 2x_2 \leq 1\\
      & & 2x_1 -2x_2 \leq 1.
    \end{array}
  \end{align*}
\end{problem}

\begin{proof}
  We begin by rewriting the above problem as follows:
  \begin{align*}
    \begin{array}{rrl}
      (N\text{-}\min) & \text{minimize} & f(\vc{x}) = x_1^2 + 6x_1x_2 -4x_1 -2x_2\\
      & \text{subject to} & g_1(\vc{x}) = x_1^2 + 2x_2 -1 \leq 0\\
      & & g_2(\vc{x}) = 2x_1 -2x_2 - 1 \leq 0.
    \end{array}
  \end{align*}
  We proceed by using the KKT-FONC to determine the possible local minimizers for this problem.
  The Lagrangian associated to this problem is given by
  \begin{align*}
    \vc{L}(\vc{x}, \vc{\mu})
    &= f(\vc{x}) + \vc{\mu}^\tran \vc{g(x)} \\
    &= f(\vc{x}) + \mu_1 g_1(\vc{x}) + \mu_2 g_2(\vc{x}) \\
    &= x_1^2 + 6x_1x_2 -4x_1 -2x_2 + \mu_1(x_1^2 + 2x_2 -1) + \mu_2(2x_1 -2x_2 - 1).
  \end{align*}
  This implies that
  \begin{align}\label{dx}
    D_{\vc{x}}L(\vc{x}, \vc{\mu}) =
    \begin{bmatrix}
      2x_1 + 6x_2 - 4 + 2\mu_1x_1 + 2\mu_2\\
      6x_1 - 2 + 2\mu_1 -2\mu_2
    \end{bmatrix}^\tran
    =
    \begin{bmatrix}
      0 \\
      0
    \end{bmatrix}^\tran.
  \end{align}
  Thus, the KKT-FONC are then written as
  \begin{enumerate}[label=\roman*.]
    \item $\mu_1, \mu_2 \geq 0$.
    \item $2x_1 + 6x_2 - 4 + 2\mu_1x_1 + 2\mu_2 = 0$.
    \item $6x_1 - 2 + 2\mu_1 -2\mu_2 = 0$.
    \item $\mu_1 g_1(\vc{x}) + \mu_2 g_2(\vc{x})  = \mu_1(x_1^2 + 2x_2 -1) + \mu_2(2x_1 -2x_2 - 1) = 0$.
    \item $g_1(\vc{x}) = x_1^2 + 2x_2 -1 \leq 0$.
    \item $g_2(\vc{x}) = 2x_1 -2x_2 - 1 \leq 0$.
  \end{enumerate}
  Solving the system \eqref{dx} for $x_1, x_2$ yields that
  \begin{align}\label{x_def}
    x_1 &= \frac{\mu_2-\mu_1+1}{3} \notag\\
    x_2 &=\frac{\mu_1^2-\mu_1\mu_2-4\mu_2+5}{9}
  \end{align}
  with $\mu_1, \mu_2\geq 0$. Using these representations of $x_1, x_2$ we see that condition iv.\
  yields three possible solutions in terms of $\mu_1, \mu_2$:
  \begin{align*}
    \text{Case 1}&: \mu_2 = \frac{13 + 12 \mu_1 + 6 \mu_1^2 - \sqrt{169 + 200 \mu_1 + 388 \mu_1^2}}{2 (14 + 3 \mu_1)}\\
    \text{Case 2}&: \mu_2 = \frac{13 + 12 \mu_1 + 6 \mu_1^2 + \sqrt{169 + 200 \mu_1 + 388 \mu_1^2}}{2 (14 + 3 \mu_1)}\\
    \text{Case 3}&: \mu_1 = -\frac{14}{3},\ \mu_2 = -\frac{3220}{789}
  \end{align*}
  We readily see that Case 3 cannot happen in light of condition i.

  Assuming Case 1 is true and using the representations of $x_1, x_2$ in \eqref{x_def},
  we see that $g_1(\vc{x}) < 0$ for $\mu_1, \mu_2 \geq 0$ implying that this constraint is inactive and that $\mu_1 = 0$.
  This implies that $\mu_2 = 0$ which in turn implies that $x_1 = 1/3$, $x_2 =  5/9$.
  However, $g_1(x_1,x_2) = 2/9 \nleq 0$ violating condition v. Thus, Case 1 cannot happen.

  Assuming Case 2 is true and using the representations of $x_1, x_2$ in \eqref{x_def},
  we again see that $g_1(\vc{x}) < 0$ for $\mu_1, \mu_2 \geq 0$ implying that this constraint is inactive and that $\mu_1 = 0$.
  This implies that $\mu_2 = 13/14$ which in turn implies that $x_1 = 9/14$, $x_2 =  1/7$.
  These values of $x_1, x_2$ satisfy conditions v.\ and vi.

  Therefore, the only vector $\vc{x}^*$ that satisfies conditions
  i.\ - vi., i.e.\ the only possible local minimizer for this problem is
  \begin{align*}
    \vc{x}^* = \begin{bmatrix}9/14 \\ 1/7\end{bmatrix}
  \end{align*}
  with associated KKT multiplier
  \begin{align*}
    \vc{\mu}^* = \begin{bmatrix}0 \\ 13/14\end{bmatrix}.
  \end{align*}

  To verify whether or not this vector is a strict local minimizer, we check the KKT-SOSC.
  For the vectors $\vc{x}^*$ and $\vc{\mu}^*$ defined above, we see that $\{i\ |\ g_i(\vc{x}^*) = 0, \mu_i^* > 0\} = \{2\}$ and that
  \begin{align*}
    \widetilde{T}(\vc{x}^*, \vc{\mu}^*) &= \{\vc{y}\in\mathbb{R}^2 \ |\ Dg_2(\vc{x}^*)\vc{y} = 0\} \\
    &= \{\vc{y}\in\mathbb{R}^2 \ |\ [2, -2]\vc{y} = 0\} \\
    &= \{\vc{y} = [y_1, y_2]^\tran\in\mathbb{R}^2 \ |\ y_1 = y_2\}.
  \end{align*}
  Further, we have, for these vectors, that
  \begin{align*}
    D_{\vc{x}}^2L(\vc{x}^*, \vc{\mu}^*) = \begin{bmatrix}2 + 2\mu_1 & 6 \\ 6 & 0 \end{bmatrix} = \begin{bmatrix}2 & 6 \\ 6 & 0 \end{bmatrix}.
  \end{align*}
  Combining we see that for $\vc{0}\neq\vc{y}\in\widetilde{T}(\vc{x}^*, \vc{\mu}^*)$, we have that
  \begin{align*}
    \vc{y}^\tran D_{\vc{x}}^2L(\vc{x}^*, \vc{\mu}^*) \vc{y} =
    \begin{bmatrix}y_1 \\ y_1\end{bmatrix}^\tran
    \begin{bmatrix}2 & 6 \\ 6 & 0 \end{bmatrix}
    \begin{bmatrix}y_1 \\ y_1\end{bmatrix}
    = 14 y_1^2 > 0
  \end{align*}
  for $y_1 \neq 0$. Therefore, $\vc{x}^* = [9/14, 1/7]^\tran$ is
  a strict local minimizer.
\end{proof}
\newpage


% Problem 3
\begin{problem}
  Consider the problem of optimizing
  \begin{align*}
    \begin{array}{rll}
      (N) & \text{minimize $($maximize$)$} & (x_1 - 2)^2 + (x_2 -1)^2 \\
      & \text{subject to} &
      \begin{array}{ll}
        x_2 - x_1^2 &\geq 0\\
        2 - x_1 - x_2 &\geq 0 \\
        x_1 &\geq 0.
      \end{array}
    \end{array}
  \end{align*}
  Let $\vc{x}^* = [0, 0]^\tran$.
  \begin{enumerate}
    \item Does $\vc{x}^*$ satisfy the KKT-FONC for minimization or maximization? What are the KKT
      multipliers?
    \item Does $\vc{x}^*$ satisfy the KKT-SOSC? Justify your answer.
  \end{enumerate}
\end{problem}

\begin{proof}
  We begin by rewriting the problem $(N)$ as
  \begin{align*}
    \begin{array}{rll}
      (N_1) & \text{minimize $($maximize$)$} & f(\vc{x}) =(x_1 - 2)^2 + (x_2 -1)^2 \\
      & \text{subject to} &
      \begin{array}{ll}
        g_1(\vc{x}) = -x_2 + x_1^2 &\leq 0\\
        g_2(\vc{x}) = -2 + x_1 + x_2 &\leq 0 \\
        g_3(\vc{x}) = -x_1 &\leq 0.
      \end{array}
    \end{array}
  \end{align*}
  For both problems, the vector $\vc{x}^*=[0,0]^\tran$ is a regular point. To see this, we note that
  $\vc{x}^*$ is feasible and the constraints $g_1(\vc{x}^*)\leq 0$ and $g_3(\vc{x}^*) \leq 0$ are both active for this vector. Since
  $\triangledown g_1(\vc{x}^*) = [0,-1]^\tran$ and $\triangledown g_3(\vc{x}^*) = [-1,0]^\tran$ are linearly independent,
  we have that $\vc{x}^*$ is a regular point as desired.

  The Lagrangian function associated to problem $(N_1\text{-min})$ is given by
  \begin{align*}
    L_{\min}(\vc{x}, \vc{\mu}) &= f(\vc{x}) + \mu_1g_1(\vc{x)} + \mu_2 g_2(\vc{x}) +\mu_3 g_3(\vc{x})\\
    &= (x_1 - 2)^2 + (x_2 -1)^2 + \mu_1(-x_2 + x_1^2) + \mu_2(-2 + x_1 + x_2) + \mu_3(-x_1)
  \end{align*}
  while the Lagrangian associated to the problem $(N_1\text{-max})$ is given by
  \begin{align*}
    L_{\max}(\vc{x}, \vc{\mu}) &= -f(\vc{x}) + \mu_1g_1(\vc{x)} + \mu_2 g_2(\vc{x}) +\mu_3 g_3(\vc{x})\\
    &= -(x_1 - 2)^2 - (x_2 -1)^2 + \mu_1(-x_2 + x_1^2) + \mu_2(-2 + x_1 + x_2) + \mu_3(-x_1).
  \end{align*}

  \begin{enumerate}
    \item Note that for problem $(N_1\text{-min})$, we have that
      \begin{align*}
        D_{\vc{x}}L_{\min}(\vc{x}, \vc{\mu}) =
        \begin{bmatrix}
          2 (x_1-2)+ 2\mu_1 x_1 + \mu_2 -\mu_3\\
          2 (x_2 - 1) + \mu_2 -\mu_1
        \end{bmatrix}^\tran,
      \end{align*}
      while for the problem $(N_1\text{-max})$, we have that
      \begin{align*}
        D_{\vc{x}}L_{\max}(\vc{x}, \vc{\mu}) =
        \begin{bmatrix}
          -2 (x_1-2)+ 2\mu_1 x_1 + \mu_2 -\mu_3 \\
          -2 (x_2 - 1) + \mu_2 -\mu_1
        \end{bmatrix}^\tran.
      \end{align*}

      The KKT-FONC for problem $(N_1\text{-min})$ then require that the following conditions hold
      \begin{enumerate}[label=\roman* a.]
        \item $\mu_1, \mu_2, \mu_3 \geq 0$.
        \item $2 (x_1-2)+ 2\mu_1 x_1 + \mu_2 -\mu_3 = 0$.
        \item $2 (x_2 - 1) + \mu_2 -\mu_1 = 0$.
        \item $\mu_1 g_1(\vc{x}) + \mu_2 g_2(\vc{x}) + \mu_3 g_3(\vc{x}) = \mu_1(-x_2 + x_1^2) + \mu_2(-2 + x_1 + x_2) + \mu_3(-x_1) = 0$.
        \item $g_1(\vc{x}) = -x_2 + x_1^2 \leq 0$.
        \item $g_2(\vc{x}) = -2 + x_1 + x_2 \leq 0$.
        \item $g_2(\vc{x}) = -x_1 \leq 0$.
      \end{enumerate}
      while the KKT-FONC for problem $(N_1\text{-max})$ require that the following similar conditions hold
      \begin{enumerate}[label=\roman* b.]
        \item $\mu_1, \mu_2, \mu_3 \geq 0$.
        \item $-2 (x_1-2)+ 2\mu_1 x_1 + \mu_2 -\mu_3 = 0$.
        \item $-2 (x_2 - 1) + \mu_2 -\mu_1 = 0$.
        \item $\mu_1 g_1(\vc{x}) + \mu_2 g_2(\vc{x}) + \mu_3 g_3(\vc{x}) = \mu_1(-x_2 + x_1^2) + \mu_2(-2 + x_1 + x_2) + \mu_3(-x_1) = 0$.
        \item $g_1(\vc{x}) = -x_2 + x_1^2 \leq 0$.
        \item $g_2(\vc{x}) = -2 + x_1 + x_2 \leq 0$.
        \item $g_2(\vc{x}) = -x_1 \leq 0$.
      \end{enumerate}
      Now suppose that $\vc{x}^* = [0,0]^\tran$. For both problems, since $\vc{x}^*$ is a
      regular point, conditions v a.\ - vii a.\ and v b.\ - vii b.\ are satisfied.
      Also, for both problems, since the constraint $g_2(\vc{x}^*)$ is inactive we have that
      by condition iv a.\ and iv b.\ that $\mu_2 = 0$.

      For the problem $(N_1\text{-min})$, conditions
      ii a.\ and iii a.\ imply that $\mu_2 - \mu_3 = -\mu_3 = 4$ and $\mu_2 - \mu_1 = -\mu_1 = 2$
      or that $\mu_1 = -2$, $\mu_2 = 0$, and $\mu_3 = -4$. However, this violates condition i a.\
      so the point $\vc{x}^*$ does not satisfy the KKT-FONC for the problem $(N_1\text{-min})$.

      For the problem $(N_1\text{-min})$, conditions
      ii a.\ and iii a.\ imply that $\mu_2 - \mu_3 = -\mu_3 = -4$ and $\mu_2 - \mu_1 = -\mu_1 = -2$
      or that $\mu_1 = 2$, $\mu_2 = 0$, and $\mu_3 = 4$. Therefore, the vector $\vc{x}^* = [0,0]^\tran$
      satisfies the KKT-FONC for the problem $(N_1\text{-max})$ with associated KKT multiplier $\vc{\mu}^* = [2,0,4]^\tran$.
    \item We now check to see if $\vc{x}^* = [0,0]^\tran$ satisfies the KKT-SOSC for the problem $(N_1\text{-max})$.
      Note that for $\vc{x}^*=[0,0]^\tran$, we have that
      \begin{align*}
        D_{\vc{x}}^2L_{\max}(\vc{x}^*, \vc{\mu}^*) = \begin{bmatrix}-2 + 2\mu_1 & 0 \\ 0 & -2 \end{bmatrix} = \begin{bmatrix}2 & 0 \\ 0 & -2 \end{bmatrix}.
      \end{align*}
      We also see that for the vectors $\vc{x}^*$ and $\vc{\mu}^*$ defined above, $\{i\ |\ g_i(\vc{x}^*) = 0, \mu_i^* > 0\} = \{1,3\}$, and that
      \begin{align*}
        \widetilde{T}(\vc{x}^*, \vc{\mu}^*) &= \{\vc{y}\in\mathbb{R}^2 \ |\ Dg_1(\vc{x}^*)\vc{y} = 0, Dg_3(\vc{x}^*)\vc{y} = 0\} \\
        &= \{\vc{y}\in\mathbb{R}^2 \ |\ [0, -1]\vc{y} = 0, [-1, 0]\vc{y} = 0\} \\
        &= \{\vc{0}\in\mathbb{R}^2\}.
      \end{align*}

      Therefore, we trivially have that the second condition in the KKT-SOSC is satisfied
      and $\vc{x}^{*} = [0,0]^\tran$ is a strict local maximizer.
  \end{enumerate}
\end{proof}



% Problem 4
\begin{problem}
  Consider the problem with equality constraint
  \begin{align*}
    \begin{array}{rl}
      \text{minimize} & f(\vc{x})\\
      \text{subject to} & \vc{h}(\vc{x}) = \vc{0}.
    \end{array}
  \end{align*}
  We can convert the above into the equivalent optimization problem
  \begin{align*}
    \begin{array}{rl}
      \text{minimize} & f(\vc{x})\\
      \text{subject to} & \frac{1}{2} \norm{\vc{h}(\vc{x})}^2 \leq 0.
    \end{array}
  \end{align*}
  Write down the KKT condition for the equivalent problem and explain why the KKT
  theorem cannot be applied in this case.
\end{problem}

\begin{proof}
  Assume $f:\mathbb{R}^n\to\mathbb{R}$ and $\vc{h}:\mathbb{R}^n \to \mathbb{R}^m$ with $m \leq n$.
  The Lagrangian associated to the equivalent problem is given by
  \begin{align*}
    L(\vc{x}, \vc{\mu}) &= f(\vc{x}) + \frac{1}{2}\vc{\mu}^\tran\norm{\vc{h}(\vc{x})}^2 \\
    &= f(\vc{x})+ \frac{\mu_1}{2}h_1(\vc{x})^2 + \dots + \frac{\mu_m}{2}h_m(\vc{x})^2.
  \end{align*}
  From this we readily see that
  \begin{align*}
    D_{\vc{x}}L(\vc{x},\vc{\mu}) =
    \begin{bmatrix}
      \frac{\partial f(\vc{x})}{\partial x_1} + \mu_1 h_1(\vc{x}) \frac{\partial h_1(\vc{x})}{\partial x_1} + \dots + \mu_m h_m(\vc{x}) \frac{\partial h_m(\vc{x})}{\partial x_1}\\
      \frac{\partial f(\vc{x})}{\partial x_2} + \mu_1 h_1(\vc{x}) \frac{\partial h_1(\vc{x})}{\partial x_2} + \dots + \mu_m h_m(\vc{x}) \frac{\partial h_m(\vc{x})}{\partial x_2}\\
      \vdots \\
      \frac{\partial f(\vc{x})}{\partial x_m} + \mu_1 h_1(\vc{x}) \frac{\partial h_1(\vc{x})}{\partial x_m} + \dots + \mu_m h_m(\vc{x}) \frac{\partial h_m(\vc{x})}{\partial x_m}\\
    \end{bmatrix}^\tran
    =
    \begin{bmatrix}
      \frac{\partial f(\vc{x})}{\partial x_1} + \sum_{i=1}^m \mu_i h_i(\vc{x}) \frac{\partial h_i(\vc{x})}{\partial x_1}\\
      \frac{\partial f(\vc{x})}{\partial x_2} + \sum_{i=1}^m \mu_i h_i(\vc{x}) \frac{\partial h_i(\vc{x})}{\partial x_2}\\
      \vdots\\
      \frac{\partial f(\vc{x})}{\partial x_m} + \sum_{i=1}^m \mu_i h_i(\vc{x}) \frac{\partial h_i(\vc{x})}{\partial x_m}
    \end{bmatrix}^\tran.
  \end{align*}
  The KKT condition for the equivalent problem can be stated as $\vc{x}^*$ is a local minimizer if
  \begin{enumerate}[label=\roman*.]
    \item The functions $f, \vc{h} \in C^1$.
    \item The point $\vc{x}^*$ is a regular point.
    \item There exist $\vc{\mu}^{*} \in \mathbb{R}^m$ such that
      \begin{enumerate}
        \item $\vc{\mu}^* \geq \vc{0}$.
        \item $D_{\vc{x}}L(\vc{x}^*,\vc{\mu}^*) = 0$.
        \item $\vc{\mu}^{*\tran}\frac{1}{2}\norm{\vc{h}(\vc{x}^*)}^2 = \mu_1 h_1(\vc{x})^2 + \dots + \mu_m h_m(\vc{x})^2 =0.$
      \end{enumerate}
  \end{enumerate}

  The KKT condition may not be applied here since no feasible point is also a regular point. To see why this
  is true, assume the point $\vc{x}$ is feasible. Then $(1/2)\norm{\vc{h}(\vc{x})}^2 \leq \vc{0}$ or
  \begin{align*}
    h_1(\vc{x})^2 + \dots + h_m(\vc{x})^2 \leq 0.
  \end{align*}
  This implies that $h_i(\vc{x}) = 0$ for $1\leq i \leq m$. Hence, the constraint is active for this
  problem. Note that
  \begin{align*}
    \bigtriangledown \frac{1}{2}\norm{\vc{h}(\vc{x})}^2 =
    \begin{bmatrix}
      h_1(\vc{x}) \frac{\partial h_1(\vc{x})}{\partial x_1} + \dots + h_m(\vc{x}) \frac{\partial h_m(\vc{x})}{\partial x_1}\\
      h_1(\vc{x}) \frac{\partial h_1(\vc{x})}{\partial x_2} + \dots + h_m(\vc{x}) \frac{\partial h_m(\vc{x})}{\partial x_2}\\
      \vdots \\
      h_1(\vc{x}) \frac{\partial h_1(\vc{x})}{\partial x_m} + \dots + h_m(\vc{x}) \frac{\partial h_m(\vc{x})}{\partial x_m}\\
    \end{bmatrix}
    =
    \begin{bmatrix}
      \sum_{i=1}^m h_i(\vc{x}) \frac{\partial h_i(\vc{x})}{\partial x_1}\\
      \sum_{i=1}^m h_i(\vc{x}) \frac{\partial h_i(\vc{x})}{\partial x_2}\\
      \vdots\\
      \sum_{i=1}^m h_i(\vc{x}) \frac{\partial h_i(\vc{x})}{\partial x_m}
    \end{bmatrix}.
  \end{align*}
  From this we clearly see that since $h_i(\vc{x}) = 0$ for $1\leq i \leq m$, we have that
  $\bigtriangledown \frac{1}{2}\norm{\vc{h}(\vc{x})}^2 = \vc{0}$ or that the vector
  $\bigtriangledown \frac{1}{2}\norm{\vc{h}(\vc{x})}^2$ is linearly dependent. Therefore, no feasible point is regular
  and the KKT condition is not applicable.
\end{proof}


\end{document}
