\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsfonts, enumitem, graphicx}
\usepackage{fancyhdr}
\usepackage{breqn}

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\renewcommand*{\proofname}{Solution}
\renewcommand{\theenumi}{\alph{enumi}}

\newcommand{\vect}[1]{\boldsymbol{#1}}
\newcommand{\bairy}{\text{Bi}}
\newenvironment{case}{%
  \let\olditem\item%
  \renewcommand\item[1][]{\olditem \textbf{##1} \\}%
  \begin{enumerate}[label=\textbf{Case \arabic*:},itemindent=*,leftmargin=0em]}{\end{enumerate}%
}

\pagestyle{fancy}
\fancyhf{}
\rhead{Homework Assignment 5}
\lhead{Matthew Tiger}
\cfoot{\thepage}


\title{Homework Assignment 5}
\author{Matthew Tiger}


\begin{document}


\maketitle


% Problem 1
\begin{problem}
  Use the method of stationary phase to find the leading behavior of the following
  integral as $x\to +\infty$:
  \begin{align*}
    I(x) = \int_0^1 e^{ixt^2}\cosh t^2 dt.
  \end{align*}
\end{problem}

\begin{proof}
  We begin by noting that the integral $I(x)$ is a generalized Fourier integral
  which can be written as
  \begin{align*}
    I(x) = \int_0^1 f(t) e^{ix\psi(t)} dt
  \end{align*}
  where $f(t) = \cosh t^2$ and $\psi(t) = t^2$. The leading asymptotic behavior of
  such integrals as $x\to+\infty$ may be found, in general, using integration by parts.
  However, this method may fail at \emph{stationary points}, i.e.\ any point on
  the interval of definition such that $\psi'(t) = 0$. For the integral $I(x)$ we note that
  $t=0$ is a stationary point. Thus, we proceed by writing $I(x)$ as follows:
  \begin{align*}
    I(x) = I_1(x) + I_2(x) = \int_0^\varepsilon f(t) e^{ix\psi(t)} dt + \int_\varepsilon^1 f(t) e^{ix\psi(t)} dt
  \end{align*}
  for some $\varepsilon > 0$.
  Since $I_2(x)$ does not have any stationary points and the
  function $f(t) = \cosh t^2 \in L^1$ over the interval $[0, 1]$, i.e.\ we have that $\int_0^1\left|f(t)\right|dt < +\infty,$
  integration by parts works on $I_2(x)$ and by the Riemann-Lebesgue lemma, $I_2(x) \to 0$ as $x \to +\infty$. Thus,
  as $x\to +\infty$,
  \begin{align*}
    I(x) \sim I_1(x) = \int_0^\varepsilon f(t) e^{ix\psi(t)} dt = \int_0^\varepsilon \cosh t^2 e^{ix t^2} dt.
  \end{align*}
  We continue by replacing $f(t)$ with $f(0) = \cosh 0 = 1$ and $\varepsilon$ with $\infty$, since
  these are the parts that contribute the most to the integral, introducing
  error terms that vanish as $x \to +\infty$ so that
  \begin{align*}
    I(x) \sim \int_0^\infty e^{ixt^2}dt
  \end{align*}
  Making the substitution
  \begin{align*}
    t = e^{i\pi/4}\left[\frac{u}{x}\right]^{1/2}
  \end{align*}
  yields that
  \begin{align*}
    \int_0^\infty e^{ixt^2}dt = e^{i\pi/4}\left[\frac{1}{x}\right]^{1/2}\frac{\Gamma(1/2)}{2} = \frac{e^{i\pi/4}}{2}\sqrt{\frac{\pi}{x}}.
  \end{align*}
  Therefore, as $x \to +\infty$,
  \begin{align*}
    I(x) \sim \int_0^\infty e^{ixt^2}dt = \frac{e^{i\pi/4}}{2}\sqrt{\frac{\pi}{x}}.
  \end{align*}
\end{proof}
\newpage


% Problem 2
\begin{problem}
  Use second-order perturbation theory to find approximations to the roots of the following equation:
  \begin{align*}
    x^3 + \varepsilon x^2 - x = 0.
  \end{align*}
\end{problem}

\begin{proof}
  If we assume that the roots of the above equation are functions of $\varepsilon$,
  then the roots $x_i$ for $i=0,1,2$ of the equation are of the form
  \begin{align*}
    x_i(\varepsilon) = \sum_{k=0}^\infty a_{i_k} \varepsilon ^k.
  \end{align*}
  Second-order perturbation theory prescribes that the roots are of the form
  $$x_i(\varepsilon) = a_{i_0} + a_{i_1} \varepsilon + a_{i_2} \varepsilon^2 + O(\varepsilon^3)$$
  where we disregard terms of order $\varepsilon^3$ or greater. Substituting $\varepsilon = 0$
  into the equation yields the new equation $x^{+3} -x = 0$, the roots of which are $-1, 0$, and $1$
  which we will say correspond to the coefficients $a_{0_0} = -1, a_{1_0} = 0, $ and $a_{2_0} = 1$.

  In order to find the values of the coefficients $a_{i_k}$ for $k \geq 1$, we substitute the expression
  $x_i(\varepsilon) = a_{i_0} + a_{i_1} \varepsilon + a_{i_2} \varepsilon^2 + O(\varepsilon^3)$ into the original equation
  yielding
  \begin{align*}
    a_{i_0}^3-a_{i_0} + (a_{i_0}^2  -a_{i_1} + 3a_{i_0}^2a_{i_1})\varepsilon + (2a_{i_0}a_{i_1} + 3a_{i_0}a_{i_1}^2 - a_{i_2} + 3a_{i_0}^2a_{i_2})\varepsilon^2 = O(\varepsilon^3).
  \end{align*}
  Since $\varepsilon$ is variable we must have that the coefficients of $\varepsilon$ in the above equation are 0.
  This yields two equations for each root:
  \begin{align*}
    a_{i_0}^2  -a_{i_1} + 3a_{i_0}^2a_{i_1} &= 0 \\
    2a_{i_0}a_{i_1} + 3a_{i_0}a_{i_1}^2 - a_{i_2} + 3a_{i_0}^2a_{i_2} &= 0.
  \end{align*}
  For the root $x_0$, we have that $a_{0_0} = -1$ and the two equations become
  \begin{align*}
    (-1)^2  -a_{0_1} + 3(-1)^2a_{0_1} &= 0 \\
    -2a_{0_1} - 3a_{0_1}^2 - a_{0_2} + 3(-1)^2a_{0_2} &= 0.
  \end{align*}
  The first equation yields that $a_{0_1} = -1/2$ and substituting into the second
  equation yields that $a_{0_2} = -1/8$. Thus, $x_0 = -1 + (-1/2)\varepsilon + (-1/8)\varepsilon^2 + O(\varepsilon^3)$.

  For the root $x_1 = 0$, we see that $a_{1_0} = 0$ and consequently from the equations that $a_{1_1} = 0$ and $a_{1_2} = 0$. Thus,
  $x_1 = 0 + 0\varepsilon + 0\varepsilon^2 + O(\varepsilon^3)$.

  Proceeding in the same way above we see for the root $x_2$, we have that $a_{2_0} = 1$ and the above two
  equations become
  \begin{align*}
    (1)^2  -a_{2_1} + 3(1)^2a_{2_1} &= 0 \\
    2a_{2_1} + 3a_{2_1}^2 - a_{2_2} + 3(1)^2a_{2_2} &= 0.
  \end{align*}
  The first equation yields that $a_{2_1} = -1/2$ and substituting into the second
  equation yields that $a_{2_2} = 1/8$. Therefore,   $x_2 = 1 + (-1/2)\varepsilon + (1/8)\varepsilon^2 + O(\varepsilon^3)$
  and we have found second-order approximations for all of the roots of the original equation.


\end{proof}
\newpage


% Problem 3
\begin{problem}
  Analyze in the limit $\varepsilon \to 0$ the roots of the polynomial
  \begin{align*}
    \varepsilon x^8 - \varepsilon^2 x^6 + x -2 = 0.
  \end{align*}
\end{problem}

\begin{proof}
  When $\varepsilon = 0$, the unperturbed equation only has one root while
  the original equation has eight roots implying that this is a singular perturbation problem.

  The root of the unperturbed problem is given by $x_0 = 2$. To find the other
  roots, we employ the method of dominant balance to the original equation and
  find a consistent balance in order to understand the order of magnitude of the roots
  as $\varepsilon \to 0$.

  As there are four terms in the original equation, there are 6
  possible dominant balances to consider:
  \begin{enumerate}[label=\roman*.]
    \item Suppose $\varepsilon x^8 \sim \varepsilon^2 x^6$ as $\varepsilon \to 0$ is the dominant balance.
      Then $x=O(\varepsilon^{1/2})$ as $\varepsilon \to 0$. However, $\varepsilon x^8 \ll 2$ as $\varepsilon \to 0$ violating the assumption
      that $\varepsilon x^8$ and $\varepsilon^2 x^6$ are the dominant terms showing that the original balance is inconsistent.
    \item Suppose $\varepsilon x^8 \sim x$ as $\varepsilon \to 0$ is the dominant balance.
      Then $x=O(\varepsilon^{-1/7})$ as $\varepsilon \to 0$. Since $2 \ll x$ and $\varepsilon^2 x^6 = O(\varepsilon^{8/7})$ is such that
      $\varepsilon^2 x^6 \ll x$, this dominant balance is consistent.
    \item Suppose $\varepsilon x^8 \sim 2$ as $\varepsilon \to 0$ is the dominant balance. Then $x=O(\varepsilon^{-1/8})$  as $\varepsilon \to 0$. However,
      $2 \ll x$ as $\varepsilon \to 0$ violating the assumption that $\varepsilon x^8$ and 2 are the dominant
      terms showing that the original balance is inconsistent.
    \item Suppose $\varepsilon^2 x^6 \sim x$ as $\varepsilon \to 0$ is the dominant balance. Then $x=O(\varepsilon^{-2/5})$  as $\varepsilon \to 0$.
      However, $\varepsilon x^8 = O(\varepsilon^{-11/5})$ is such that $x \ll \varepsilon x^8$ violating the assumption that $\varepsilon^2 x^6$ and $x$ are
      the dominant terms showing that the original balance is inconsistent.
    \item Suppose $\varepsilon^2 x^6 \sim 2$ as $\varepsilon \to 0$ is the dominant balance. Then $x=O(\varepsilon^{-1/3})$ as $\varepsilon \to 0$.
      However, $\varepsilon x^8 = O(\varepsilon^{-5/3})$ is such that $2 \ll \varepsilon x^8$ violating the assumption that $\varepsilon^2 x^6$ and $2$ are
      the dominant terms showing that the original balance is inconsistent.
    \item Suppose $x \sim 2$ as $\varepsilon \to 0$ is the dominant balance. This balance is consistent since $x=O(1)$ and we recover the original root with this equation.
  \end{enumerate}

  The above analysis suggests that, from the only consistent dominant balance that
  provides additional information, the magnitudes of the missing roots are
  $O(\varepsilon^{-1/7})$ as $\varepsilon \to 0$. Making the scale transformation
  $x = \varepsilon^{-1/7}y$ and substituting into the original equation yields
  \begin{align}\label{regular}
    y^8 - \varepsilon^{9/7}y^6 + y - 2\varepsilon^{1/7} = 0
  \end{align}
  The unperturbed problem now does not vanish and the problem is now a regular perturbation problem.
  Thus, a perturbation expansion exists for the roots $y$ in terms of powers of $\varepsilon^{1//7}$, i.e.\
  the roots to \eqref{regular} are of the form
  \begin{align*}
    y = \sum_{n=0}^\infty y_n \left(\varepsilon^{1/7}\right)^n.
  \end{align*}
\end{proof}
\newpage


% Problem 4
\begin{problem}
  Solve perturbatively
  \begin{align*}
    \begin{cases}
      y'' = (\sin x)y &\\
      y(0) = 1 &\\
      y'(0) = 1
    \end{cases}.
  \end{align*}
  Is the resulting perturbation series uniformly valid for $0\leq x \leq \infty$? Why?
\end{problem}

\begin{proof}
  We begin by introducing the small perturbation factor $\varepsilon$ into the problem as follows:
  \begin{align*}
    y'' = \varepsilon(\sin x) y,\quad y(0) = 1,\ y'(0) = 1.
  \end{align*}
  Next, we assume a solution $y(x)$ exists in the form
  \begin{align}\label{ivp}
    y(x) = \sum_{n=0}^\infty \varepsilon^n y_n(x)
  \end{align}
  where $y_0(0) = 1$, $y_0'(0) = 1$, and $y_n(0) = y_n'(0) = 0$ for $n > 0$. Using
  the perturbation expansion \eqref{ivp} and substituting into the perturbed problem
  yields after comparing the coefficients of $\varepsilon$ that
  \begin{align*}
    \begin{cases}
      y_0''(x) = 0 & y_0(0) = 1,\ y_0'(0) = 1 \\
      y_n''(x) = (\sin x) y_{n-1}(x) & y_n(0) = 0,\ y_n'(0) =0\quad \text{for $n>0$}.
    \end{cases}
  \end{align*}
  Thus, the solution to the zeroth-order problem is simply $y_0(x) = c_1x + c_2$
  where the values of $c_1$ and $c_2$ are determined by the initial conditions
  $y_0(0) = 1,\ y_0'(0) = 1$. Therefore,  the solution
  to the zeroth order problem is $y_0(x) = x + 1$.

  The solution to the $n$-th order problem can be found simply by integration:
  \begin{align*}
    y_n(x) = \int_{0}^{x} dx_2\int_{0}^{x_2} (\sin x_1) y_{n-1}(x_1) dx_1.
  \end{align*}
  Thus, from this equation we can see that for $n > 0$
  \begin{align*}
    y_n(x) &= \int_0^{x}d{x_{2n}}\int_0^{x_{x_{2n}}}d{x_{2n-1}}(\sin x_{2n-1})\int_0^{x_{2n-1}}d_{x_{2n-2}}\int_0^{x_{x_{2n-2}}}d_{x_{2n-3}}(\sin x_{2n-3})\cdots \\
    &\quad \cdots\int_{0}^{x_3} dx_2\int_{0}^{x_2} (\sin x_1) (1 + x_1) dx_1
  \end{align*}
  and therefore that our perturbation series is
  \begin{align*}
    y(x) = 1 + x + \left(\int_{0}^{x} dx_2\int_{0}^{x_2} (\sin x_1) (1+ x_1) dx_1\right)\varepsilon + y_2(x)\varepsilon^2 + \dots .
  \end{align*}

  Since $\left|\sin x\right| \leq 1$, using the above formula, we see that the   $N$-th term of the perturbation series is bounded above, i.e.\
  \begin{align*}
    \left|\varepsilon^N y_N(x)\right| \leq \frac{\varepsilon^N x^{2N} (1 + |x|)}{(2N)!}.
  \end{align*}
  Thus, the series is convergent for all finite $x$. However, this series is not uniformly valid over the interval
  $0 \leq x \leq \infty$. To see why, note that the leading behavior of the perturbation series
  is that of $1 + x = O(x)$. However, for $\varepsilon > 0$, the perturbation series
  is a linear combination of $\sin $ and $\cos$ functions and therefore a
  linear combination of exponentially increasing and decreasing functions.
  For large $x$ these exponentially increasing and decreasing functions are not negligible and contribute to
  the perturbation series. This is a change in character of the perturbation series from the unperturbed problem and thus we may
  conclude that the perturbation series is not uniformly valid over the interval $0 \leq x \leq \infty$.
\end{proof}
\newpage


% Problem 5
\begin{problem}
  Find leading-order uniform asymptotic approximations to the solution of the
  following equation in the limit $\varepsilon \to 0^+$:
  \begin{align*}
    &\varepsilon y'' + (x^2 + 1)y' - x^3y=0 \\
    &y(0) = 1,\ y(1) = 1.
  \end{align*}
\end{problem}

\begin{proof}
  In obtaining a leading-order uniform asymptotic approximation to the solution
  of the above differential equation, we make the assumption that $y(x)$ develops
  an isolated boundary layer in the neighborhood of $x=0$.

  Outside of this boundary layer there are no rapid variations of $y(x)$ and we
  may assume that $\varepsilon y''(x)$ is negligible as $\varepsilon \to 0^+$.
  Thus, we obtain the approximation
  \begin{align*}
    (x^2+1)y'_{\text{out}}(x) = x^3 y_{\text{out}}(x),
  \end{align*}
  the solution of which is
  \begin{align*}
    y_{\text{out}}(x) &= c_1\exp\left[\int_x^1 \frac{t^3}{t^2+1} dt\right] = \frac{c_1\sqrt{x^2+1}e^{\frac{1-x^2}{2}}}{\sqrt{2}}.
  \end{align*}
  Since $x=1$ is outside of the boundary layer we have that $y_{\text{out}}(x)$ must satisfy the boundary condition
  $y_{\text{out}}(1)=1$. This implies that $c_1 = 1$. This solution is a uniform aproximation
  to the solution $y(x)$ as $\varepsilon \to 0^+$ on the interval $\delta \ll x \leq 1$ for some $\delta > 0$.

  In order to determine the behavior of the solution near the boundary layer, we make the following
  approximations $(x^2 + 1)y' \sim y'$ and $-x^3y \sim 0$ so that the approximation of the inner solution becomes
  \begin{align*}
    \varepsilon y''_{\text{in}}(x) + y'_{\text{in}}(x) = 0.
  \end{align*}
  The solution to this second-order differential equation with constant cofficients is simply
  \begin{align*}
    y_{\text{in}}(x) = c_1 + c_2 e^{-x/\varepsilon}.
  \end{align*}
  Since we must have that the boundary condition is met, we see that $y_{\text{in}}(0) = 1$.
  This implies that $c_1 + c_2 = 1$ or that
  \begin{align*}
    y_{\text{in}}(x) = 1 + c_2\left(e^{-x/\varepsilon}-1\right).
  \end{align*}

  The boundary layer occurs when $x=O(\varepsilon)$. In order to asymptotically match the inner and outer solutions,
  let's assume that $x=O(\varepsilon^{1/2})$. Thus, as $\varepsilon \to 0^+$, we see that
  \begin{align*}
    y_{\text{in}}(x) &\sim 1 - c_2 \\
    y_{\text{out}}(x) &\sim y_{\text{out}}(0) = \frac{e^{1/2}}{\sqrt{2}}.
  \end{align*}
  In order for the approximation to be valid, we require that $c_2 = 1 - \frac{e^{1/2}}{\sqrt{2}}$.
  Thus, as $\varepsilon \to 0^+$, the boundary layer approximation is given by
  \begin{align*}
    y(x) &\sim \frac{   \sqrt{x^2+1}e^{\frac{1-x^2}{2}}}{\sqrt{2}} \quad \text{for $0<x\leq 1$} \\
    y(x) &\sim e^{-x/\varepsilon} + \frac{e^{1/2}}{\sqrt{2}}\left(1-e^{-x/\varepsilon}\right)
  \end{align*}
  A uniform approximation valid for all $0\leq x \leq 1$ is then given by
  \begin{align*}
    y(x) &= y_{\text{out}}(x) + y_{\text{in}}(x) - y_{\text{match}}(x) \\
    &= \frac{   \sqrt{x^2+1}e^{\frac{1-x^2}{2}}}{\sqrt{2}} + e^{-x/\varepsilon} + \frac{e^{1/2}}{\sqrt{2}}\left(1-e^{-x/\varepsilon}\right) - \frac{e^{1/2}}{\sqrt{2}}\\
    &= \frac{   \sqrt{x^2+1}e^{\frac{1-x^2}{2}}}{\sqrt{2}} + \left(1 - \frac{e^{1/2}}{\sqrt{2}}\right)e^{-x/\varepsilon},
  \end{align*}
  where $y_{\text{match}}(x) = 1 - (1 -y_{\text{out}}(0))$.
\end{proof}
\newpage


% Problem 6
\begin{problem}
  Obtain a uniform approximation accurate to order $\varepsilon ^2$ as $\varepsilon \to 0^+$
  for the problem
  \begin{align*}
      &\varepsilon y'' + (1+x)^2 y' + y = 0 \\
      &y(0) = 1,\ y(1) = 1.
  \end{align*}
\end{problem}

\begin{proof}
\end{proof}
\newpage


% Problem 7
\begin{problem}
  For what real values of the constant $\alpha$ does the singular perturbation
  problem
  \begin{align*}
    &\varepsilon y''(x) + y'(x) - x^\alpha y(x) = 0  \\
    &y(0) = 1,\ y(1) = 1.
  \end{align*}
  have a solution with a boundary layer near $x=0$ as $\varepsilon \to 0^+$?
\end{problem}

\begin{proof}
\end{proof}
\newpage


\end{document}