\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsfonts, enumitem, graphicx}
\usepackage{fancyhdr}
\usepackage{breqn}

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\renewcommand*{\proofname}{Solution}
\renewcommand{\theenumi}{\alph{enumi}}

\newcommand{\vect}[1]{\boldsymbol{#1}}
\newcommand{\bairy}{\text{Bi}}
\newenvironment{case}{%
  \let\olditem\item%
  \renewcommand\item[1][]{\olditem \textbf{##1} \\}%
  \begin{enumerate}[label=\textbf{Case \arabic*:},itemindent=*,leftmargin=0em]}{\end{enumerate}%
}

\pagestyle{fancy}
\fancyhf{}
\rhead{Homework Assignment 5}
\lhead{Matthew Tiger}
\cfoot{\thepage}


\title{Homework Assignment 5}
\author{Matthew Tiger}


\begin{document}


\maketitle


% Problem 1
\begin{problem}
  Use the method of stationary phase to find the leading behavior of the following
  integral as $x\to +\infty$:
  \begin{align*}
    I(x) = \int_0^1 e^{ixt^2}\cosh t^2 dt.
  \end{align*}
\end{problem}

\begin{proof}
  We begin by noting that the integral $I(x)$ is a generalized Fourier integral
  which can be written as
  \begin{align*}
    I(x) = \int_0^1 f(t) e^{ix\psi(t)} dt
  \end{align*}
  where $f(t) = \cosh t^2$ and $\psi(t) = t^2$. The leading asymptotic behavior of
  such integrals as $x\to+\infty$ may be found, in general, using integration by parts.
  However, this method may fail at \emph{stationary points}, i.e.\ any point on
  the interval of definition such that $\psi'(t) = 0$. For the integral $I(x)$ we note that
  $t=0$ is a stationary point. Thus, we proceed by writing $I(x)$ as follows:
  \begin{align*}
    I(x) = I_1(x) + I_2(x) = \int_0^\varepsilon f(t) e^{ix\psi(t)} dt + \int_\varepsilon^1 f(t) e^{ix\psi(t)} dt
  \end{align*}
  for some $\varepsilon > 0$.
  Since $I_2(x)$ does not have any stationary points and the
  function $f(t) = \cosh t^2 \in L^1$ over the interval $[0, 1]$, i.e.\ we have that $\int_0^1\left|f(t)\right|dt < +\infty,$
  integration by parts works on $I_2(x)$ and by the Riemann-Lebesgue lemma, $I_2(x) \to 0$ as $x \to +\infty$. Thus,
  as $x\to +\infty$,
  \begin{align*}
    I(x) \sim I_1(x) = \int_0^\varepsilon f(t) e^{ix\psi(t)} dt = \int_0^\varepsilon \cosh t^2 e^{ix t^2} dt.
  \end{align*}
  We continue by replacing $f(t)$ with $f(0) = \cosh 0 = 1$ and $\varepsilon$ with $\infty$, since
  these are the parts that contribute the most to the integral, introducing
  error terms that vanish as $x \to +\infty$ so that
  \begin{align*}
    I(x) \sim \int_0^\infty e^{ixt^2}dt
  \end{align*}
  Making the substitution
  \begin{align*}
    t = e^{i\pi/4}\left[\frac{u}{x}\right]^{1/2}
  \end{align*}
  yields that
  \begin{align*}
    \int_0^\infty e^{ixt^2}dt = e^{i\pi/4}\left[\frac{1}{x}\right]^{1/2}\frac{\Gamma(1/2)}{2} = \frac{e^{i\pi/4}}{2}\sqrt{\frac{\pi}{x}}.
  \end{align*}
  Therefore, as $x \to +\infty$,
  \begin{align*}
    I(x) \sim \int_0^\infty e^{ixt^2}dt = \frac{e^{i\pi/4}}{2}\sqrt{\frac{\pi}{x}}.
  \end{align*}
\end{proof}
\newpage


% Problem 2
\begin{problem}
  Use second-order perturbation theory to find approximations to the roots of the following equation:
  \begin{align*}
    x^3 + \varepsilon x^2 - x = 0.
  \end{align*}
\end{problem}

\begin{proof}
  If we assume that the roots of the above equation are functions of $\varepsilon$,
  then the roots $x_i$ for $i=0,1,2$ of the equation are of the form
  \begin{align*}
    x_i(\varepsilon) = \sum_{k=0}^\infty a_{i_k} \varepsilon ^k.
  \end{align*}
  Second-order perturbation theory prescribes that the roots are of the form
  $$x_i(\varepsilon) = a_{i_0} + a_{i_1} \varepsilon + a_{i_2} \varepsilon^2 + O(\varepsilon^3)$$
  where we disregard terms of order $\varepsilon^3$ or greater. Substituting $\varepsilon = 0$
  into the equation yields the new equation $x^-3 -x = 0$, the roots of which are $-1, 0$, and $1$
  which we will say correspond to the coefficients $a_{0_0} = -1, a_{1_0} = 0, $ and $a_{2_0} = 1$.

  In order to find the values of the coefficients $a_{i_k}$ for $k \geq 1$, we substitute the expression
  $x_i(\varepsilon) = a_{i_0} + a_{i_1} \varepsilon + a_{i_2} \varepsilon^2 + O(\varepsilon^3)$ into the original equation
  yielding
  \begin{align*}
    a_{i_0}^3-a_{i_0} + (a_{i_0}^2  -a_{i_1} + 3a_{i_0}^2a_{i_1})\varepsilon + (2a_{i_0}a_{i_1} + 3a_{i_0}a_{i_1}^2 - a_{i_2} + 3a_{i_0}^2a_{i_2})\varepsilon^2 = O(\varepsilon^3).
  \end{align*}
  Since $\varepsilon$ is variable we must have that the coefficients of $\varepsilon$ in the above equation are 0.
  This yields two equations for each root:
  \begin{align*}
    a_{i_0}^2  -a_{i_1} + 3a_{i_0}^2a_{i_1} &= 0 \\
    2a_{i_0}a_{i_1} + 3a_{i_0}a_{i_1}^2 - a_{i_2} + 3a_{i_0}^2a_{i_2} &= 0.
  \end{align*}
  For the root $x_0$, we have that $a_{0_0} = -1$ and the two equations become
  \begin{align*}
    (-1)^2  -a_{0_1} + 3(-1)^2a_{0_1} &= 0 \\
    -2a_{0_1} - 3a_{0_1}^2 - a_{0_2} + 3(-1)^2a_{0_2} &= 0.
  \end{align*}
  The first equation yields that $a_{0_1} = -1/2$ and substituting into the second
  equation yields that $a_{0_2} = -1/8$. Thus, $x_0 = -1 + (-1/2)\varepsilon + (-1/8)\varepsilon^2 + O(\varepsilon^3)$.

  For the root $x_1 = 0$, we see that $a_{1_0} = 0$ and consequently from the equations that $a_{1_1} = 0$ and $a_{1_2} = 0$. Thus,
  $x_1 = 0 + 0\varepsilon + 0\varepsilon^2 + O(\varepsilon^3)$.

  Proceeding in the same way above we see for the root $x_2$, we have that $a_{2_0} = 1$ and the above two
  equations become
  \begin{align*}
    (1)^2  -a_{2_1} + 3(1)^2a_{2_1} &= 0 \\
    2a_{2_1} + 3a_{2_1}^2 - a_{2_2} + 3(1)^2a_{2_2} &= 0.
  \end{align*}
  The first equation yields that $a_{2_1} = -1/2$ and substituting into the second
  equation yields that $a_{2_2} = 1/8$. Therefore,   $x_2 = 1 + (-1/2)\varepsilon + (1/8)\varepsilon^2 + O(\varepsilon^3)$
  and we have found second-order approximations for all of the roots of the original equation.


\end{proof}
\newpage


% Problem 3
\begin{problem}
  Analyze in the limit $\varepsilon \to 0$ the roots of the polynomial
  \begin{align*}
    \varepsilon x^8 - \varepsilon^2 x^6 + x -2 = 0.
  \end{align*}
\end{problem}

\begin{proof}
\end{proof}
\newpage


% Problem 4
\begin{problem}
  Solve perturbatively
  \begin{align*}
    \begin{cases}
      y'' = (\sin x)y &\\
      y(0) = 1 &\\
      y'(0) = 1
    \end{cases}.
  \end{align*}
  Is the resulting perturbation series uniformly valid for $0\leq x \leq \infty$? Why?
\end{problem}

\begin{proof}
\end{proof}
\newpage


% Problem 5
\begin{problem}
  Find leading-order uniform asymptotic approximations to the solution of the
  following equation in the limit $\varepsilon \to 0^+$:
  \begin{align*}
    &\varepsilon y'' + (x^2 + 1)y' - x^3y=0 \\
    &y(0) = 1,\ y(1) = 1.
  \end{align*}
\end{problem}

\begin{proof}
\end{proof}
\newpage


% Problem 6
\begin{problem}
  Obtain a uniform approximation accurate to order $\varepsilon ^2$ as $\varepsilon \to 0^+$
  for the problem
  \begin{align*}
      &\varepsilon y'' + (1+x)^2 y' + y = 0 \\
      &y(0) = 1,\ y(1) = 1.
  \end{align*}
\end{problem}

\begin{proof}
\end{proof}
\newpage


% Problem 7
\begin{problem}
  For what real values of the constant $\alpha$ does the singular perturbation
  problem
  \begin{align*}
    &\varepsilon y''(x) + y'(x) - x^\alpha y(x) = 0  \\
    &y(0) = 1,\ y(1) = 1.
  \end{align*}
  have a solution with a boundary layer near $x=0$ as $\varepsilon \to 0^+$?
\end{problem}

\begin{proof}
\end{proof}
\newpage


\end{document}