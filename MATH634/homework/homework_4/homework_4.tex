\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsfonts, breqn}


\theoremstyle{definition}
\newtheorem{problem}{Problem}
\renewcommand*{\proofname}{Solution}
\newenvironment{custompbm}[1]
  {\renewcommand\theproblem{#1}\problem}
  {\endproblem}
\renewcommand{\theenumi}{\alph{enumi}}


\newcommand{\E}{\text{E}}
\newcommand{\V}{\text{Var}}
\newcommand{\Co}[2]{\text{Cov}({#1}, {#2})}
\newcommand{\pdf}{\text{pdf}}
\newcommand{\pmf}{\text{pmf}}
\newcommand{\me}{\mathrm{e}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\vect}[1]{\boldsymbol{#1}}
\newcommand{\mx}[1][t]{\mu_X({#1})}
\newcommand{\gx}[2]{\gamma_X({#1}, {#2})}


\title{Homework Assignment 4}
\author{Matthew Tiger}


\begin{document}


\maketitle


% Problem 2.3
\begin{custompbm}{2.3}
  Find the ACVF of the time series $X_t = Z_t + aZ_{t-1} + bZ_{t-2}$ where
  $Z_t \sim WN(0, \sigma^2)$ when:
  \begin{enumerate}
    \item $a=0.3$, $b=-0.4$, and $\sigma^2=1$.
    \item $a=-1.2$, $b=-1.6$, and $\sigma^2=0.25$.
  \end{enumerate}
\end{custompbm}

\begin{proof}
  The ACVF of the time series $\{X_t\}$, $\gamma_X(h)$, is by definition:
  \begin{align}\label{acvf}
    \gamma_X(h)
    &= \Co{X_{t+h}}{X_t} \notag \\
    &= \Co{Z_{t+h} + aZ_{t+h-1} + bZ_{t+h-2}}{Z_{t} + aZ_{t-1} + bZ_{t-2}} \notag \\
    &= \Co{Z_{t+h}}{Z_t} + a\Co{Z_{t+h}}{Z_{t-1}} + b\Co{Z_{t+h}}{Z_{t-2}} \notag \\
    & \hspace{5mm} + a\Co{Z_{t+h-1}}{Z_t} + a^2\Co{Z_{t+h-1}}{Z_{t-1}} + ab\Co{Z_{t+h-1}}{Z_{t-2}} \notag \\
    & \hspace{5mm} + b\Co{Z_{t+h-2}}{Z_t} + ab\Co{Z_{t+h-2}}{Z_{t-1}} + b^2\Co{Z_{t+h-2}}{Z_{t-2}}.
  \end{align}
  Using \eqref{acvf}, we can see that since $Z_t \sim WN(0, \sigma^2)$,
  \begin{align*}
    \gamma_X(h) =
    \begin{cases}
      (1 + a^2 + b^2)\sigma^2 & \text{if $h=0$}\\
      a(1 + b)\sigma^2 & \text{if $h=\pm1$}\\
      b\sigma^2 & \text{if $h=\pm2$}\\
      0 & \text{otherwise}
    \end{cases}.
  \end{align*}
  Therefore, when
  \begin{enumerate}
    \item $a=0.3$, $b=-0.4$, and $\sigma^2=1$, the ACVF of $\{X_t\}$ is:
      \[
        \begin{cases}
          1.25 & \text{if $h=0$}\\
          0.18 & \text{if $h=\pm1$}\\
          -0.4 & \text{if $h=\pm2$}\\
          0 & \text{otherwise}
        \end{cases}
      \]
    \item $a=-1.2$, $b=-1.6$, and $\sigma^2=0.25$, the ACVF of $\{X_t\}$ is:
      \[
        \begin{cases}
          1.25 & \text{if $h=0$}\\
          0.18 & \text{if $h=\pm1$}\\
          -0.4 & \text{if $h=\pm2$}\\
          0 & \text{otherwise}
        \end{cases}
      \]
  \end{enumerate}
\end{proof}


% Problem 2.5


\begin{custompbm}{2.5}
  Suppose that $\{X_t, t=0, \pm1, \dots\}$ is stationary and that $|\theta|<1$.
  Show that for each fixed $n$ the sequence
  \[
    S_m = \sum_{j=1}^{m} \theta ^ j X_{n-j}
  \]
  is convergent absolutely and in mean square as $m \to \infty$.
\end{custompbm}

\begin{proof}
  Let $a_j = \theta ^ j X_{n-j}$. Then to see that $S_m$ is convergent absolutely
  as $m \to \infty$, notice that
  \begin{align*}
    S_m = \sum_{j=1}^{m} |a_j|
    &= \sum_{j=1}^{m} |\theta ^ j X_{n-j}| \\
    &= \sum_{j=1}^{m} |\theta| ^ j |X_{n-j}|\\
    &\leq \sum_{j=1}^{m} |X_{n-j}|
  \end{align*}

  To see that $S_m$ is convergent in the mean square, it suffices to show that
  $\E(S_m - S_l)^2 \to 0$ as $m, l \to \infty$.

  Without loss of generality, assume that $m > l > 0$. Notice that
  $S_m - S_l = \sum_{j=1}^m a_j - \sum_{j=1}^n a_j = \sum_{j=l+1}^{m} a_j$.
  Thus, $$\E(S_m - S_l) = \E(\sum_{j=l+1}^{m} a_j) = \sum_{j=l+1}^m \E(a_j).$$
  It is clear that $\E(a_j) = \E(\theta^j X_{n-j}) = \theta^j \E(X_{n-j})$. Since
  $\{X_t\}$ is a stationary time series, its expectation does not depend on $t$,
  so say $\E(X_{n-j}) = \mu_X$. Then
  \begin{align*}
    \E(S_m - S_l)
    &= \sum_{j=l+1}^m \theta^j\E(X_{n-j}) \\
    &=\mu_X \sum_{j=l+1}^m \theta^j \\
    &= \frac{\mu_X\theta^{l+1}(1-\theta^{m-l-1})}{1-\theta}
  \end{align*}
  Since $|\theta| < 1$, it is clear then that $\E(S_m - S_l)^2 \to 0$ as $m,l \to \infty$
  showing that $S_m$ is convergent in mean square for any $n$.
\end{proof}


\end{document}
