\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsfonts, breqn, graphicx}


\theoremstyle{definition}
\newtheorem{problem}{Problem}
\renewcommand*{\proofname}{Solution}
\newenvironment{custompbm}[1]
  {\renewcommand\theproblem{#1}\problem}
  {\endproblem}
\renewcommand{\theenumi}{\alph{enumi}}


\newcommand{\E}{\text{E}}
\newcommand{\V}{\text{Var}}
\newcommand{\Co}[2]{\text{Cov}\left({#1}, {#2}\right)}
\newcommand{\pdf}{\text{pdf}}
\newcommand{\pmf}{\text{pmf}}
\newcommand{\me}{\mathrm{e}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\vect}[1]{\boldsymbol{#1}}
\newcommand{\mx}[1][t]{\mu_X({#1})}
\newcommand{\gx}[2]{\gamma_X({#1}, {#2})}


\title{Homework Assignment 11}
\author{Matthew Tiger}


\begin{document}


\maketitle


\begin{custompbm}{5.1}
  The sunspot numbers $\{X_t, t=1,\dots, 100\}$, filed as \texttt{SUNSPOTS.TSM},
  have sample autocovariances $\hat{\gamma}(0) = 1382.2$, $\hat{\gamma}(1) = 1114.4$,
  $\hat{\gamma}(2) = 591.73$, and $\hat{\gamma}(3) = 96.216$. Use these values to
  find the Yule-Walker estimates of $\phi_1$, $\phi_2$, and $\sigma^2$ in the model
  \[
    Y_t = \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + Z_t, \quad \{Z_t\} \sim \text{WN}(0, \sigma^2),
  \]
  for the mean-corrected series $Y_t = X_t - 46.93$, $t=1,\dots, 100$. Assuming the
  data really are a realization of an AR(2) process, find 95\% confidence intervals
  for $\phi_1$ and $\phi_2$.
\end{custompbm}

\begin{proof}
  We wish to find $\hat{\phi}_1, \hat{\phi}_2,$ and $\hat{\sigma}^2$ given $\hat{\gamma}(0)$,
  $\hat{\gamma}(1)$, and $\hat{\gamma}(2)$. By the Yule-Walker equations for sample
  autocovariances,

  \[
    \begin{bmatrix}
      \hat{\gamma}(0) & \hat{\gamma}(1) \\
      \hat{\gamma}(1) & \hat{\gamma}(0) \\
    \end{bmatrix}
    \begin{bmatrix}
      \hat{\phi}_1 \\
      \hat{\phi}_2 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
      \hat{\gamma}(1) \\
      \hat{\gamma}(2) \\
    \end{bmatrix}.
  \]
  Solving this system yields $\hat{\phi}_1 = 1.31755$ and $\hat{\phi}_2 = -0.634168$.
  Using the Yule-Walker equation $\hat{\sigma}^2 = \hat{\gamma}(0) - \hat{\phi}_1 \hat{\gamma}(1) - \hat{\phi}_2 \hat{\gamma}(2)$,
  we see that $\hat{\sigma}^2 = 289.2$.

  Since our sample size $n=100$ is large, a 95\% confidence interval for the parameter $\phi_j$ is given by
  \[
   \hat{\phi}_j \pm \Phi_{1-\frac{\alpha}{2}}n ^{-1/2} \hat{\nu}_{jj}^{1/2}
  \]
  where $\Phi_{1-\frac{\alpha}{2}} = 1.96$ and $\hat{\nu}_{jj}$ is the $j$-th element on the diagonal of
  $\hat{\sigma}^2\Gamma_2^{-1}$ for $j=1,2$. Using this formula, we see that
  $\nu_{jj} = 0.5979$ for $j=1,2$ and 95\% confidence intervals for the model
  parameters are given by
  \begin{align*}
    (1.1660, 1.4961)& \quad \text{for $\phi_1$} \\
    (-0.7858, -0.4827)& \quad \text{for $\phi_2$} .
  \end{align*}
\end{proof}


\begin{custompbm}{5.2}
  From the information given in the previous problem, use the Durbin-Levinson
  algorithm to compute the sample partial autocorrelations $\hat{\phi}_{11}$, $\hat{\phi}_{22}$,
  and $\hat{\phi}_{33}$ of the sunspot series. Is the value of $\hat{\phi}_{33}$ compatible
  with the hypothesis that the data are generated by an AR(2) process? (Use significance level
  $\alpha = 0.05$.)
\end{custompbm}

\begin{proof}
  Note that the sample partial autocorrelation function is given by $\hat{\alpha}(0) = 1$ and
  $\hat{\alpha}(n) = \hat{\phi}_{nn}$. We can use the Durbin-Levinson algorithm
  to compute $\hat{\phi}_{nn}$. Following the recursive equations presented by the
  algorithm, we have that for $n = 1$,
  \begin{align*}
    \hat{\phi}_{11} &= \hat{\gamma}(1)/\hat{\gamma}(0) = 0.8063 \\
    \hat{\nu}_1 &= \hat{\nu}_0 (1 - \hat{\rho}(1)^2) = 483.7140.
  \end{align*}
  Similarly, for $n = 2$, we have that
  \begin{align*}
    \hat{\phi}_{22} &= \nu_1^{-1}(\hat{\gamma}(2) - \hat{\phi}_{11}\hat{\gamma}(1)) = -0.6342\\
    \hat{\phi}_{21} &= \hat{\phi}_{11} - \hat{\phi}_{22} \hat{\phi}_{11} = 1.3175\\
    \hat{\nu}_2 &= \hat{\nu}_1 (1 - \hat{\phi}_{22}^2) = 289.1791.
  \end{align*}
  Thus, for $n=3$,
  \[
    \hat{\phi}_{33} = \nu_2^{-1}(\hat{\gamma}(3) - \hat{\phi}_{21}\hat{\gamma}(2) - \hat{\phi}_{22}\hat{\gamma}(1)) = 0.0806\\.
  \]
  Note that a process is an AR($2$) process if $\alpha(n) = 0$ for $n > 2$. As we have a sample
  size of $n=100$, we have for a significance level $\alpha = 0.05$ the identically-zero
  bounds $0 \pm 1.96/\sqrt{100}$. Using these bounds we see that
  $\hat{\alpha}(3) = \hat{\phi}_{33} = 0.0806$ which does in fact fall within our
  identically-zero bounds. So, the data suggests $\hat{\alpha}(3)$ is identically 0 which
  supports the hypothesis that the data is a realization of an AR(2) process.
\end{proof}


\begin{custompbm}{5.3}
  Consider the AR(2) process $\{X_t\}$ satisfying
  \[
    X_t - \phi X_{t-1} - \phi^2 X_{t-2} = Z_t, \quad \{Z_t\} \sim \text{WN}(0, \sigma^2).
  \]
  \begin{enumerate}
    \item For what values of $\phi$ is this a causal process?
    \item The following sample moments were computed after observing $X_1,\dots, X_{200}$:
      \[
        \hat{\gamma}(0) = 6.06, \quad \hat{\rho}(1) = 0.687.
      \]
      Find estimates of $\phi$ and $\sigma^2$ by solving the Yule-Walker equations. (If
      you find more than one solution, choose the one that is causal.)
  \end{enumerate}
\end{custompbm}

\begin{proof}
  The characteristic polynomial of this AR(2) process is given by $\phi(z) = 1 - \phi z - \phi^2 z^2$.
  The AR(2) process $\{X_t\}$ is causal if the roots of $\phi(z)$ occur outside the unit circle.
  Note that the roots of $\phi(z)$ are given by $z_1 = \frac{-1 + \sqrt{5}}{2}$
  and $z_2 = \frac{-1 - \sqrt{5}}{2}$. Note that $|z_i| > 1$ for $i=1,2$ if
  $|\phi| < \frac{-1 + \sqrt{5}}{2}$. Therefore, the process is causal if
  $|\phi| < \frac{-1 + \sqrt{5}}{2} = 0.618034$.

  Given $\hat{\gamma}(0) = 6.06$ and $\hat{\rho}(1) = \frac{\hat{\gamma}(1)}{\hat{\gamma}(0)} = 0.687$,
  we see that $\hat{\gamma}(1) = 4.16322$. By the Yule-Walker equations,
  \[
    \begin{bmatrix}
      \hat{\gamma}(0) & \hat{\gamma}(1) \\
      \hat{\gamma}(1) & \hat{\gamma}(0) \\
    \end{bmatrix}
    \begin{bmatrix}
      \phi \\
      \phi^2 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
      \hat{\gamma}(1) \\
      \hat{\gamma}(2) \\
    \end{bmatrix}.
  \]
  The solution to this system of equations suggests that
  $\phi = 1.30106 - 0.214696 \hat{\gamma}(2)$ and $\phi^2 = -0.893828 + 0.3125\hat{\gamma}(2)$.
  Therefore,
  \[
    1.30106 - 0.214696 \hat{\gamma}(2) = \sqrt{\phi^2} = \pm \sqrt{-0.893828 + 0.3125\hat{\gamma}(2)}.
  \]
  This suggests that $\hat{\gamma}(2) = 15.2107$ or $\hat{\gamma}(2) = 3.68918$. For $\hat{\gamma}(2) = 15.2107$,
  we have that $\phi = -1.96462$. As this value of $\phi$ violates the causality of the process,
  we reject this value so $\hat{\gamma}(2) = 3.68918$ and $\phi = 0.509008$. These values of
  $\phi$ and $\hat{\gamma}(2)$ can be used to show that
  \[
    \sigma^2 = \hat{\gamma}(0) - \phi \hat{\gamma}(1) - \phi^2 \hat{\gamma}(2) = 2.98506.
  \]
\end{proof}


\begin{custompbm}{5.4}
  Two hundred observations of a time series $X_1,\dots, X_{200}$, gave the following
  sample statistics:

  \[
  \begin{array}{ll}
    \text{sample mean:} & \bar{x}_{200} = 3.82; \\
    \text{sample variance:} & \hat{\gamma}(0) = 1.15; \\
    \text{sample ACF:} & \hat{\rho}(1) = 0.427;\\
    & \hat{\rho}(2) = 0.475;\\
    & \hat{\rho}(3) = 0.169.\\
  \end{array}
  \]

  \begin{enumerate}
    \item Based on these sample statistics, is it reasonable to suppose that
      $\{X_t - \mu\}$ is white noise?
    \item Assuming $\{X_t - \mu\}$ can be modeled as an AR(2) process
      \[
        X_t - \mu - \phi_1(X_{t-1} - \mu) - \phi_2(X_{t-2} - \mu) = Z_t,
      \]
      where $\{Z_t\} \sim \text{IID}(0, \sigma^2)$, find estimates of $\mu$, $\phi_1$, $\phi_2$, $\sigma^2$.
    \item Would you conclude that $\mu = 0$?
    \item Construct 95\% confidence intervals for $\phi_1$ and $\phi_2$.
    \item Assuming that the data were generated from an AR(2) model, derive estimates for the PACF for all lags $h \geq 1$.
  \end{enumerate}
\end{custompbm}

\begin{proof}
  \begin{enumerate}
    \item The process $\{X_t - \mu\}$ is white noise with mean 0 if $\rho(i) = 0$ for $i > 0$.
      As the process $\{X_t - \mu\}$ is zero-mean, a 95\% confidence interval for zero
      with 200 samples is given by
      \[
        \left(-\frac{1.96}{\sqrt(200)}, \frac{1.96}{\sqrt(200)}\right) = (-0.1386, 0.1386).
      \]
      As the sample autocorrelations fall outside this interval, they are not identically
      0 and we reject the hypothesis that the process $\{X_t - \mu\}$ is white noise.
    \item By the Yule-Walker equations,
      \[
        \begin{bmatrix}
          \hat{\phi}_1 \\
          \hat{\phi}_1 \\
        \end{bmatrix}
        =
        \begin{bmatrix}
          \hat{\rho}(0) & \hat{\rho}(1)\\
          \hat{\rho}(1) & \hat{\rho}(0) \\
        \end{bmatrix} ^{-1}
        \begin{bmatrix}
          \hat{\rho}(1) \\
          \hat{\rho}(2) \\
        \end{bmatrix}
      \]
      so we see that $\hat{\phi}_1 = 0.2742$ and $\hat{\phi}_2 = 0.3579$ and
      \[
      \hat{\sigma}^2 = \hat{\gamma}(0)\left[1 -   \begin{bmatrix}
          \hat{\rho}(1) \\
          \hat{\rho}(2) \\
        \end{bmatrix}^{\intercal}
        =
        \begin{bmatrix}
          \hat{\rho}(0) & \hat{\rho}(1)\\
          \hat{\rho}(1) & \hat{\rho}(0) \\
        \end{bmatrix} ^{-1}
        \begin{bmatrix}
          \hat{\rho}(1) \\
          \hat{\rho}(2) \\
        \end{bmatrix}\right] = 0.8199.
      \]
      An estimate for $\mu$ is given by the sample mean, i.e. $\hat{\mu} = \bar{x}_{200} = 3.82.$
    \item As our sample size $n=200$ is large, the sample mean is normally distribute with mean $\mu$ and
      variance $\sum \gamma(i) \approx 3.61$. Thus, a 95\% confidence interval for the mean
      is given by (3.5567, 4.0833). As $\mu = 0$ falls outside this interval, we reject the
      hypothesis that $\mu = 0$.
    \item   Since our sample size $n=200$ is large, a 95\% confidence interval for the parameter $\phi_j$ is given by
      \[
        \hat{\phi}_j \pm \Phi_{1-\frac{\alpha}{2}}n ^{-1/2} \hat{\nu}_{jj}^{1/2}
      \]
      where $\Phi_{1-\frac{\alpha}{2}} = 1.96$ and $\hat{\nu}_{jj}$ is the $j$-th element on the diagonal of
      $\hat{\sigma}^2\Gamma_2^{-1}$ for $j=1,2$. Using this formula, we see that
      $\nu_{jj} = 0.8719$ for $j=1,2$ and 95\% confidence intervals for the model
      parameters are given by
      \begin{align*}
        (0.1450, 0.4050)& \quad \text{for $\phi_1$} \\
        (0.2279, 0.4879)& \quad \text{for $\phi_2$}.
      \end{align*}
    \item If the data were generated from an AR(2) process then, by the Durbin-Levinson algorithm,
      $\hat{\alpha}(1) = \hat{\phi}_{11} = \hat{\rho}(1) = 0.427$,
      $\hat{\alpha}(2) = \hat{\phi}_{22} = 0.3579$, and
      $\hat{\alpha}(h) = 0 $ for $h \geq 3$.
  \end{enumerate}
\end{proof}


\end{document}
