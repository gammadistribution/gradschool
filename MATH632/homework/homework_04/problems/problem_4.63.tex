\begin{problem}{4.63}
  For the Markov chain with states 1, 2, 3, 4 whose transition probability matrix
  $\bold{P}$ is as listed below find $f_{i3}$ and $s_{i3}$
  for $i=1, 2, 3$.
  \begin{align*}
    \bold{P} =
    \begin{bmatrix}
      0.4 & 0.2 & 0.1 & 0.3 \\
      0.1 & 0.5 & 0.2 & 0.2 \\
      0.3 & 0.4 & 0.2 & 0.1 \\
      0\phantom{.1} & 0\phantom{.1} & 0\phantom{.1} & 1\phantom{.1}
    \end{bmatrix}
  \end{align*}
\end{problem}

\begin{proof}
  From this matrix it is clear that states 1, 2, and 3 all communicate. However, state 4 communicates
  with neither states 1,2, nor 3. Since $P_{44}^n = 1$ for all $n > 0$, we easily see that
  $\sum_{n=1}^\infty P_{44}^n = \infty$, i.e.\ state 4 is a recurrent state. Note that
  recurrence is a property shared by equivalence classes under the relation communicates.
  We see that since states 1, 2, and 3 do not communicate with state 4, but all communicate with each other,
  these states must be transient.

  Let $s_{ij}$ denote the expected number of time periods that the Markov chain is in
  state $j$ given that it started in state $i$ and let $\bold{P}_T$ be the transition matrix
  from transient states into transient states. Since states 1, 2, and 3 are the transient states of the Markov
  chain, we have that
  \begin{align*}
    \bold{P}_T =
    \begin{bmatrix}
      0.4 & 0.2 & 0.1  \\
      0.1 & 0.5 & 0.2  \\
      0.3 & 0.4 & 0.2
    \end{bmatrix}.
  \end{align*}
  If $\bold{S}$ is the matrix of values $s_{ij}$ for $i,j = 1, 2, 3$, then $\bold{S} = (\bold{I} - \bold{P}_T)^{-1}.$
  Thus, we see that
  \begin{align*}
    \bold{S} =
    \begin{bmatrix}
       \phantom{-}0.6 & -0.2 & -0.1 \\
      -0.1 &  \phantom{-}0.5 & -0.2 \\
      -0.3 & -0.4 &  \phantom{-}0.8 \\
    \end{bmatrix}^{-1} =
    \begin{bmatrix}
      2.20690 & 1.37931 & 0.62069 \\
      0.96552 & 3.10345 & 0.89655 \\
      1.31034 & 2.06897 & 1.93103 \\
    \end{bmatrix}.
  \end{align*}
  Therefore, we have that
  \begin{align*}
    s_{13} = 0.62069,\quad
    s_{23} = 0.89655,\quad
    s_{33} = 1.93103.
  \end{align*}

  If $f_{ij}$ is the probability that the Markov chain ever transitions to state $j$ given that it starts
  in state $i$, then
  \begin{align*}
    f_{ij} = \frac{s_{ij} - \delta_{i,j}}{s_{jj}},
  \end{align*}
  where $\delta_{i,j}$ is the Kronecker delta such that $\delta_{i,j} =1$ if $i=j$ and $\delta_{i,j} =0$ otherwise. Thus,
  \begin{align*}
    f_{13} &= \frac{s_{13} - \delta_{1,3}}{s_{33}} =  \frac{0.62069}{1.93103} = 0.321429\\
    f_{23} &= \frac{s_{23} - \delta_{2,3}}{s_{33}} =  \frac{0.89655}{1.93103} = 0.464286\\
    f_{33} &= \frac{s_{33} - \delta_{3,3}}{s_{33}} =  \frac{0.93103}{1.93103} = 0.482142.
  \end{align*}
\end{proof}
\newpage
