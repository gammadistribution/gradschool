\begin{problem}{4.35}
  Consider a Markov chain with states $0, 1, 2, 3, 4$. Suppose $P_{04} = 1$; and suppose
  that when the chain is in state $i$, with $i > 0$, the next state is equally
  likely to be any of the states $0, 1, \dots, i-1$. Find the limiting probabilities of
  this Markov chain.
\end{problem}

\begin{proof}
\end{proof}
\newpage
